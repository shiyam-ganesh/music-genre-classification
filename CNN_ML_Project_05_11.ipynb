{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CLicXfjIiZhX",
        "outputId": "8377b104-70e6-480b-e84d-a7e03e07b065"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "/content/drive/MyDrive/Data\n"
          ]
        }
      ],
      "source": [
        "import math\n",
        "import json\n",
        "import librosa\n",
        "import os\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from google.colab import drive\n",
        "import tensorflow as tf\n",
        "drive.mount('/content/drive')\n",
        "%cd /content/drive/MyDrive/Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oUevkU0WitWV"
      },
      "outputs": [],
      "source": [
        "\n",
        "SAMPLE_RATE = 22050\n",
        "TRACK_DURATION = 30 # measured in seconds\n",
        "SAMPLES_PER_TRACK = SAMPLE_RATE * TRACK_DURATION\n",
        "\n",
        "\n",
        "def preprocess(dataset_path, num_mfcc=40, n_fft=2048, hop_length=512, num_segments=10):\n",
        "\n",
        "    # dictionary to store mapping, labels, and MFCCs\n",
        "    data = {\n",
        "        \"mapping\":[],\n",
        "        \"labels\": [],\n",
        "        \"mfcc\": []\n",
        "    }\n",
        "\n",
        "    samples_per_segment = int(SAMPLES_PER_TRACK / num_segments)\n",
        "    num_mfcc_vectors_per_segment = math.ceil(samples_per_segment / hop_length)\n",
        "\n",
        "    # loop through all genre sub-folder\n",
        "    for i, (dirpath, dirnames, filenames) in enumerate(os.walk(dataset_path)):\n",
        "\n",
        "        # ensure we're processing a genre sub-folder level\n",
        "        if dirpath is not dataset_path:\n",
        "\n",
        "            # save genre label (i.e., sub-folder name) in the mapping\n",
        "            semantic_label = dirpath.split(\"/\")[-1]\n",
        "            data[\"mapping\"].append(semantic_label)\n",
        "            print(\"\\nProcessing: {}\".format(semantic_label))\n",
        "\n",
        "            # process all audio files in genre sub-dir\n",
        "            for f in filenames:\n",
        "\n",
        "\t\t# load audio file\n",
        "\n",
        "                file_path = os.path.join(dirpath, f)\n",
        "\n",
        "                if file_path != '/content/drive/My Drive/Data/genres_original/jazz/jazz.00054.wav':\n",
        "\n",
        "                    signal, sample_rate = librosa.load(file_path, sr=SAMPLE_RATE)\n",
        "\n",
        "\n",
        "                    # process all segments of audio file\n",
        "                    for d in range(num_segments):\n",
        "\n",
        "                        # calculate start and finish sample for current segment\n",
        "                        start = samples_per_segment * d\n",
        "                        finish = start + samples_per_segment\n",
        "\n",
        "                        # extract mfcc\n",
        "                        #mfcc = librosa.feature.mfcc(signal[start:finish], sample_rate, n_mfcc=num_mfcc, n_fft=n_fft, hop_length=hop_length)\n",
        "                        mfcc = librosa.feature.mfcc(y=signal[start:finish], sr=sample_rate, n_mfcc=num_mfcc, n_fft=n_fft, hop_length=hop_length)\n",
        "\n",
        "                        mfcc = mfcc.T\n",
        "\n",
        "                        # store only mfcc feature with expected number of vectors\n",
        "                        if len(mfcc) == num_mfcc_vectors_per_segment:\n",
        "                            data[\"mfcc\"].append(mfcc.tolist())\n",
        "                            data[\"labels\"].append(i-1)\n",
        "                            #print(\"{}, segment:{}\".format(file_path, d+1))\n",
        "    return data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TVED7OTBjAYI",
        "outputId": "b0996544-084c-4e38-ff6f-a0d1104f29d1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Processing: jazz\n",
            "\n",
            "Processing: pop\n",
            "\n",
            "Processing: rock\n",
            "\n",
            "Processing: metal\n",
            "\n",
            "Processing: blues\n",
            "\n",
            "Processing: reggae\n",
            "\n",
            "Processing: country\n",
            "\n",
            "Processing: disco\n",
            "\n",
            "Processing: classical\n",
            "\n",
            "Processing: hiphop\n"
          ]
        }
      ],
      "source": [
        "dataset_path='/content/drive/My Drive/Data/genres_original'\n",
        "mfcc_data=preprocess(dataset_path)\n",
        "x=np.array(mfcc_data[\"mfcc\"])\n",
        "y=np.array(mfcc_data[\"labels\"])\n",
        "z=np.array(mfcc_data[\"mapping\"])\n",
        "x=x.reshape(x.shape[0],x.shape[1],x.shape[2],1)\n",
        "y=tf.keras.utils.to_categorical(y,num_classes=10)\n",
        "x_train,x_test,y_train,y_test=train_test_split(x,y,test_size=0.25)\n",
        "x_train,x_val,y_train,y_val=train_test_split(x_train,y_train,test_size=0.2)\n",
        "y_train[y_train==10]=9\n",
        "y_val[y_val==10]=9\n",
        "y_test[y_test==10]=9\n",
        "input_shape=x_train.shape[1:]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dM9JNMbak5HF"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras import models, layers\n",
        "\n",
        "cnn_model = models.Sequential([\n",
        "    layers.Conv2D(32, (3, 3), activation='relu', padding='valid', input_shape=input_shape),\n",
        "    layers.MaxPooling2D(2, padding='same'),\n",
        "\n",
        "    layers.Conv2D(128, (3, 3), activation='relu', padding='valid'),\n",
        "    layers.MaxPooling2D(2, padding='same'),\n",
        "    layers.Dropout(0.3),\n",
        "\n",
        "    layers.Conv2D(128, (3, 3), activation='relu', padding='valid'),\n",
        "    layers.MaxPooling2D(2, padding='same'),\n",
        "    layers.Dropout(0.3),\n",
        "\n",
        "    layers.GlobalAveragePooling2D(),\n",
        "    layers.Dense(512, activation='relu'),\n",
        "    layers.Dense(10, activation='softmax')\n",
        "])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FGv5nggYoD4A",
        "outputId": "c5e24bfb-756f-4621-ceca-d14226ad4b7e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d (Conv2D)             (None, 128, 38, 32)       320       \n",
            "                                                                 \n",
            " max_pooling2d (MaxPooling2  (None, 64, 19, 32)        0         \n",
            " D)                                                              \n",
            "                                                                 \n",
            " conv2d_1 (Conv2D)           (None, 62, 17, 128)       36992     \n",
            "                                                                 \n",
            " max_pooling2d_1 (MaxPoolin  (None, 31, 9, 128)        0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 31, 9, 128)        0         \n",
            "                                                                 \n",
            " conv2d_2 (Conv2D)           (None, 29, 7, 128)        147584    \n",
            "                                                                 \n",
            " max_pooling2d_2 (MaxPoolin  (None, 15, 4, 128)        0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 15, 4, 128)        0         \n",
            "                                                                 \n",
            " global_average_pooling2d (  (None, 128)               0         \n",
            " GlobalAveragePooling2D)                                         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 512)               66048     \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 10)                5130      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 256074 (1000.29 KB)\n",
            "Trainable params: 256074 (1000.29 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "cnn_model.compile(loss='binary_crossentropy',optimizer='adam',metrics='acc')\n",
        "cnn_model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oRFjwlcLoT5H",
        "outputId": "70bb0b3c-215a-4371-9794-e68a387f9e9e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/40\n",
            "188/188 - 99s - loss: 0.2655 - acc: 0.3597 - val_loss: 0.2131 - val_acc: 0.4973 - 99s/epoch - 527ms/step\n",
            "Epoch 2/40\n",
            "188/188 - 90s - loss: 0.2018 - acc: 0.5358 - val_loss: 0.1817 - val_acc: 0.6048 - 90s/epoch - 479ms/step\n",
            "Epoch 3/40\n",
            "188/188 - 91s - loss: 0.1774 - acc: 0.6116 - val_loss: 0.1876 - val_acc: 0.5794 - 91s/epoch - 484ms/step\n",
            "Epoch 4/40\n",
            "188/188 - 90s - loss: 0.1630 - acc: 0.6535 - val_loss: 0.1517 - val_acc: 0.6809 - 90s/epoch - 481ms/step\n",
            "Epoch 5/40\n",
            "188/188 - 92s - loss: 0.1496 - acc: 0.6832 - val_loss: 0.1599 - val_acc: 0.6769 - 92s/epoch - 487ms/step\n",
            "Epoch 6/40\n",
            "188/188 - 92s - loss: 0.1410 - acc: 0.6984 - val_loss: 0.1426 - val_acc: 0.7196 - 92s/epoch - 487ms/step\n",
            "Epoch 7/40\n",
            "188/188 - 96s - loss: 0.1313 - acc: 0.7301 - val_loss: 0.1262 - val_acc: 0.7457 - 96s/epoch - 513ms/step\n",
            "Epoch 8/40\n",
            "188/188 - 97s - loss: 0.1217 - acc: 0.7568 - val_loss: 0.1255 - val_acc: 0.7623 - 97s/epoch - 514ms/step\n",
            "Epoch 9/40\n",
            "188/188 - 93s - loss: 0.1100 - acc: 0.7788 - val_loss: 0.1125 - val_acc: 0.7870 - 93s/epoch - 495ms/step\n",
            "Epoch 10/40\n",
            "188/188 - 97s - loss: 0.1031 - acc: 0.7945 - val_loss: 0.1065 - val_acc: 0.7924 - 97s/epoch - 517ms/step\n",
            "Epoch 11/40\n",
            "188/188 - 93s - loss: 0.0961 - acc: 0.8157 - val_loss: 0.0960 - val_acc: 0.8158 - 93s/epoch - 493ms/step\n",
            "Epoch 12/40\n",
            "188/188 - 93s - loss: 0.0933 - acc: 0.8167 - val_loss: 0.0971 - val_acc: 0.8198 - 93s/epoch - 496ms/step\n",
            "Epoch 13/40\n",
            "188/188 - 97s - loss: 0.0862 - acc: 0.8379 - val_loss: 0.0988 - val_acc: 0.8151 - 97s/epoch - 516ms/step\n",
            "Epoch 14/40\n",
            "188/188 - 92s - loss: 0.0797 - acc: 0.8469 - val_loss: 0.0947 - val_acc: 0.8298 - 92s/epoch - 491ms/step\n",
            "Epoch 15/40\n",
            "188/188 - 88s - loss: 0.0717 - acc: 0.8681 - val_loss: 0.0976 - val_acc: 0.8211 - 88s/epoch - 469ms/step\n",
            "Epoch 16/40\n",
            "188/188 - 87s - loss: 0.0672 - acc: 0.8721 - val_loss: 0.0995 - val_acc: 0.8164 - 87s/epoch - 462ms/step\n",
            "Epoch 17/40\n",
            "188/188 - 90s - loss: 0.0644 - acc: 0.8847 - val_loss: 0.0855 - val_acc: 0.8451 - 90s/epoch - 481ms/step\n",
            "Epoch 18/40\n",
            "188/188 - 91s - loss: 0.0584 - acc: 0.8978 - val_loss: 0.0971 - val_acc: 0.8364 - 91s/epoch - 485ms/step\n",
            "Epoch 19/40\n",
            "188/188 - 87s - loss: 0.0564 - acc: 0.8992 - val_loss: 0.0911 - val_acc: 0.8438 - 87s/epoch - 465ms/step\n",
            "Epoch 20/40\n",
            "188/188 - 87s - loss: 0.0536 - acc: 0.9080 - val_loss: 0.0858 - val_acc: 0.8505 - 87s/epoch - 463ms/step\n",
            "Epoch 21/40\n",
            "188/188 - 91s - loss: 0.0491 - acc: 0.9172 - val_loss: 0.0846 - val_acc: 0.8565 - 91s/epoch - 483ms/step\n",
            "Epoch 22/40\n",
            "188/188 - 92s - loss: 0.0452 - acc: 0.9269 - val_loss: 0.0825 - val_acc: 0.8718 - 92s/epoch - 487ms/step\n",
            "Epoch 23/40\n",
            "188/188 - 92s - loss: 0.0445 - acc: 0.9296 - val_loss: 0.0783 - val_acc: 0.8732 - 92s/epoch - 490ms/step\n",
            "Epoch 24/40\n",
            "188/188 - 97s - loss: 0.0418 - acc: 0.9316 - val_loss: 0.0920 - val_acc: 0.8498 - 97s/epoch - 517ms/step\n",
            "Epoch 25/40\n",
            "188/188 - 93s - loss: 0.0393 - acc: 0.9366 - val_loss: 0.0810 - val_acc: 0.8698 - 93s/epoch - 496ms/step\n",
            "Epoch 26/40\n",
            "188/188 - 93s - loss: 0.0354 - acc: 0.9449 - val_loss: 0.0798 - val_acc: 0.8732 - 93s/epoch - 493ms/step\n",
            "Epoch 27/40\n",
            "188/188 - 94s - loss: 0.0338 - acc: 0.9508 - val_loss: 0.0861 - val_acc: 0.8658 - 94s/epoch - 501ms/step\n",
            "Epoch 28/40\n",
            "188/188 - 96s - loss: 0.0328 - acc: 0.9501 - val_loss: 0.0826 - val_acc: 0.8858 - 96s/epoch - 513ms/step\n",
            "Epoch 29/40\n",
            "188/188 - 93s - loss: 0.0319 - acc: 0.9513 - val_loss: 0.0789 - val_acc: 0.8772 - 93s/epoch - 494ms/step\n",
            "Epoch 30/40\n",
            "188/188 - 97s - loss: 0.0281 - acc: 0.9601 - val_loss: 0.0786 - val_acc: 0.8899 - 97s/epoch - 517ms/step\n",
            "Epoch 31/40\n",
            "188/188 - 92s - loss: 0.0293 - acc: 0.9576 - val_loss: 0.0810 - val_acc: 0.8919 - 92s/epoch - 491ms/step\n",
            "Epoch 32/40\n",
            "188/188 - 92s - loss: 0.0260 - acc: 0.9638 - val_loss: 0.0809 - val_acc: 0.8932 - 92s/epoch - 489ms/step\n",
            "Epoch 33/40\n",
            "188/188 - 98s - loss: 0.0360 - acc: 0.9484 - val_loss: 0.0784 - val_acc: 0.8939 - 98s/epoch - 521ms/step\n",
            "Epoch 34/40\n",
            "188/188 - 91s - loss: 0.0215 - acc: 0.9723 - val_loss: 0.0858 - val_acc: 0.8825 - 91s/epoch - 486ms/step\n",
            "Epoch 35/40\n",
            "188/188 - 92s - loss: 0.0236 - acc: 0.9683 - val_loss: 0.0832 - val_acc: 0.8872 - 92s/epoch - 491ms/step\n",
            "Epoch 36/40\n",
            "188/188 - 92s - loss: 0.0260 - acc: 0.9651 - val_loss: 0.0827 - val_acc: 0.8925 - 92s/epoch - 491ms/step\n",
            "Epoch 37/40\n",
            "188/188 - 96s - loss: 0.0214 - acc: 0.9715 - val_loss: 0.1000 - val_acc: 0.8792 - 96s/epoch - 512ms/step\n",
            "Epoch 38/40\n",
            "188/188 - 90s - loss: 0.0259 - acc: 0.9628 - val_loss: 0.0789 - val_acc: 0.8992 - 90s/epoch - 481ms/step\n",
            "Epoch 39/40\n",
            "188/188 - 91s - loss: 0.0191 - acc: 0.9753 - val_loss: 0.0933 - val_acc: 0.8852 - 91s/epoch - 486ms/step\n",
            "Epoch 40/40\n",
            "188/188 - 87s - loss: 0.0215 - acc: 0.9710 - val_loss: 0.0832 - val_acc: 0.8885 - 87s/epoch - 465ms/step\n"
          ]
        }
      ],
      "source": [
        "\n",
        "history=cnn_model.fit(x_train,y_train,validation_data=(x_val,y_val),epochs=40,verbose=2,batch_size=32)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_loss, test_acc = cnn_model.evaluate(x_test, y_test, verbose=2)\n",
        "print(\"\\nTest accuracy:\", test_acc)\n"
      ],
      "metadata": {
        "id": "p3Ep0lpgHOlC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "02d6f7b9-2e31-49fb-cfca-4e66ac31af05"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "79/79 - 8s - loss: 0.0794 - acc: 0.8915 - 8s/epoch - 103ms/step\n",
            "\n",
            "Test accuracy: 0.8914697766304016\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def predict(model, X, y):\n",
        "    \"\"\"Predict a single sample using the trained model.\n",
        "    :param model: Trained classifier\n",
        "    :param X: Input data\n",
        "    :param y: One-hot encoded target label\n",
        "    \"\"\"\n",
        "\n",
        "    # add a dimension to input data for sample - model.predict() expects a 4d array in this case\n",
        "    X = X[np.newaxis, ...]  # array shape (1, 130, 40, 1)\n",
        "\n",
        "    # perform prediction\n",
        "    prediction = model.predict(X)\n",
        "\n",
        "    # get index with max value\n",
        "    predicted_index = np.argmax(prediction, axis=1)\n",
        "\n",
        "    # convert the one-hot encoded label back to the original integer label\n",
        "    original_label = np.argmax(y)\n",
        "\n",
        "    # get mappings for target and predicted label\n",
        "    target = z[original_label]\n",
        "    predicted = z[predicted_index[0]]  # Note: use predicted_index[0] to access the single predicted label\n",
        "\n",
        "    print(\"Target: {}, Predicted label: {}\".format(target, predicted))\n",
        "\n",
        "X_to_predict = x_test[100]\n",
        "y_to_predict = y_test[100]\n",
        "\n",
        "# predict sample\n",
        "predict(cnn_model, X_to_predict, y_to_predict)\n",
        "#display(x_test[199].shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BeRr73AWdump",
        "outputId": "6c044494-df05-4b2b-a481-5a98e12b9fae"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 25ms/step\n",
            "Target: hiphop, Predicted label: hiphop\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cnn_model.save('CNN_GTZAN.h5')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UkaqqexZfH7S",
        "outputId": "c27fe670-791d-4d48-81d8-1e6dcf8f85c0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3079: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}