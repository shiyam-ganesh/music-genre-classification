{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8fiFL24LZRv1"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "drssrTmy9rZE",
        "outputId": "9d9644ea-f5cd-4e7a-fbd5-65e6116f7d2c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "/content/drive/MyDrive/Data\n"
          ]
        }
      ],
      "source": [
        "import math\n",
        "import json\n",
        "import librosa\n",
        "import os\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "%cd /content/drive/MyDrive/Data"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "SAMPLE_RATE = 22050\n",
        "TRACK_DURATION = 30 # measured in seconds\n",
        "SAMPLES_PER_TRACK = SAMPLE_RATE * TRACK_DURATION\n",
        "\n",
        "\n",
        "def preprocess(dataset_path, num_mfcc=40, n_fft=2048, hop_length=512, num_segments=10):\n",
        "\n",
        "    # dictionary to store mapping, labels, and MFCCs\n",
        "    data = {\n",
        "        \"mapping\":[],\n",
        "        \"labels\": [],\n",
        "        \"mfcc\": []\n",
        "    }\n",
        "\n",
        "    samples_per_segment = int(SAMPLES_PER_TRACK / num_segments)\n",
        "    num_mfcc_vectors_per_segment = math.ceil(samples_per_segment / hop_length)\n",
        "\n",
        "    # loop through all genre sub-folder\n",
        "    for i, (dirpath, dirnames, filenames) in enumerate(os.walk(dataset_path)):\n",
        "\n",
        "        # ensure we're processing a genre sub-folder level\n",
        "        if dirpath is not dataset_path:\n",
        "\n",
        "            # save genre label (i.e., sub-folder name) in the mapping\n",
        "            semantic_label = dirpath.split(\"/\")[-1]\n",
        "            data[\"mapping\"].append(semantic_label)\n",
        "            print(\"\\nProcessing: {}\".format(semantic_label))\n",
        "\n",
        "            # process all audio files in genre sub-dir\n",
        "            for f in filenames:\n",
        "\n",
        "\t\t# load audio file\n",
        "\n",
        "                file_path = os.path.join(dirpath, f)\n",
        "\n",
        "                if file_path != '/content/drive/My Drive/Data/genres_original/jazz/jazz.00054.wav':\n",
        "\n",
        "                    signal, sample_rate = librosa.load(file_path, sr=SAMPLE_RATE)\n",
        "\n",
        "\n",
        "                    # process all segments of audio file\n",
        "                    for d in range(num_segments):\n",
        "\n",
        "                        # calculate start and finish sample for current segment\n",
        "                        start = samples_per_segment * d\n",
        "                        finish = start + samples_per_segment\n",
        "\n",
        "                        #extract mfcc\n",
        "                        #mfcc = librosa.feature.mfcc(signal[start:finish], sample_rate, n_mfcc=num_mfcc, n_fft=n_fft, hop_length=hop_length)\n",
        "                        mfcc = librosa.feature.mfcc(y=signal[start:finish], sr=sample_rate, n_mfcc=num_mfcc, n_fft=n_fft, hop_length=hop_length)\n",
        "\n",
        "                        mfcc = mfcc.T\n",
        "\n",
        "                        # store only mfcc feature with expected number of vectors\n",
        "                        if len(mfcc) == num_mfcc_vectors_per_segment:\n",
        "                            data[\"mfcc\"].append(mfcc.tolist())\n",
        "                            data[\"labels\"].append(i-1)\n",
        "                            #print(\"{}, segment:{}\".format(file_path, d+1))\n",
        "    return data"
      ],
      "metadata": {
        "id": "Y5_sd1r9-Ipx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset_path='/content/drive/My Drive/Data/genres_original'\n",
        "\n",
        "mfcc_data=preprocess(dataset_path)\n",
        "x=np.array(mfcc_data[\"mfcc\"])\n",
        "y=np.array(mfcc_data[\"labels\"])\n",
        "z=np.array(mfcc_data[\"mapping\"])\n",
        "x_train,x_test,y_train,y_test=train_test_split(x,y,test_size=0.25)\n",
        "x_train,x_val,y_train,y_val=train_test_split(x_train,y_train,test_size=0.2)\n",
        "input_shape=(x_train.shape[1],x_train.shape[2])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cxqrOj9fAQtZ",
        "outputId": "24f655a0-5307-4cfb-b563-b8142aaa7ce4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Processing: jazz\n",
            "\n",
            "Processing: pop\n",
            "\n",
            "Processing: rock\n",
            "\n",
            "Processing: metal\n",
            "\n",
            "Processing: blues\n",
            "\n",
            "Processing: reggae\n",
            "\n",
            "Processing: country\n",
            "\n",
            "Processing: disco\n",
            "\n",
            "Processing: classical\n",
            "\n",
            "Processing: hiphop\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "model=tf.keras.Sequential()\n",
        "model.add(tf.keras.layers.LSTM(64,input_shape=input_shape,return_sequences=True))\n",
        "model.add(tf.keras.layers.LSTM(64))\n",
        "model.add(tf.keras.layers.Dense(64,activation=\"relu\"))\n",
        "model.add(tf.keras.layers.Dense(10,activation=\"softmax\"))"
      ],
      "metadata": {
        "id": "jUKLHa6uLFsF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer=tf.keras.optimizers.Adam(lr=0.001)\n",
        "model.compile(optimizer=optimizer,loss='sparse_categorical_crossentropy',metrics=['accuracy'])\n",
        "model.summary()\n",
        "model.fit(x_train,y_train,validation_data=(x_val,y_val),batch_size=32,epochs=60,verbose=2)\n",
        "model.save(\"GTZAN_LSTM.h5\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yQZhu6ZdKMNe",
        "outputId": "4ac56396-731c-4c0a-8889-6a2b695686da"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " lstm (LSTM)                 (None, 130, 64)           26880     \n",
            "                                                                 \n",
            " lstm_1 (LSTM)               (None, 64)                33024     \n",
            "                                                                 \n",
            " dense (Dense)               (None, 64)                4160      \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 10)                650       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 64714 (252.79 KB)\n",
            "Trainable params: 64714 (252.79 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n",
            "Epoch 1/60\n",
            "188/188 - 38s - loss: 1.7043 - accuracy: 0.3837 - val_loss: 1.5403 - val_accuracy: 0.4419 - 38s/epoch - 202ms/step\n",
            "Epoch 2/60\n",
            "188/188 - 32s - loss: 1.3261 - accuracy: 0.5211 - val_loss: 1.4710 - val_accuracy: 0.4666 - 32s/epoch - 170ms/step\n",
            "Epoch 3/60\n",
            "188/188 - 30s - loss: 1.2180 - accuracy: 0.5694 - val_loss: 1.2740 - val_accuracy: 0.5427 - 30s/epoch - 162ms/step\n",
            "Epoch 4/60\n",
            "188/188 - 37s - loss: 1.0810 - accuracy: 0.6166 - val_loss: 1.2141 - val_accuracy: 0.5728 - 37s/epoch - 199ms/step\n",
            "Epoch 5/60\n",
            "188/188 - 29s - loss: 0.9799 - accuracy: 0.6523 - val_loss: 1.1311 - val_accuracy: 0.5935 - 29s/epoch - 155ms/step\n",
            "Epoch 6/60\n",
            "188/188 - 31s - loss: 0.9056 - accuracy: 0.6698 - val_loss: 1.0849 - val_accuracy: 0.6275 - 31s/epoch - 163ms/step\n",
            "Epoch 7/60\n",
            "188/188 - 32s - loss: 0.8213 - accuracy: 0.7101 - val_loss: 1.0148 - val_accuracy: 0.6475 - 32s/epoch - 169ms/step\n",
            "Epoch 8/60\n",
            "188/188 - 33s - loss: 0.7322 - accuracy: 0.7468 - val_loss: 0.9089 - val_accuracy: 0.6976 - 33s/epoch - 174ms/step\n",
            "Epoch 9/60\n",
            "188/188 - 29s - loss: 0.6424 - accuracy: 0.7815 - val_loss: 0.9400 - val_accuracy: 0.6889 - 29s/epoch - 153ms/step\n",
            "Epoch 10/60\n",
            "188/188 - 31s - loss: 0.6046 - accuracy: 0.7934 - val_loss: 0.8527 - val_accuracy: 0.7216 - 31s/epoch - 164ms/step\n",
            "Epoch 11/60\n",
            "188/188 - 32s - loss: 0.5343 - accuracy: 0.8184 - val_loss: 0.8463 - val_accuracy: 0.7210 - 32s/epoch - 170ms/step\n",
            "Epoch 12/60\n",
            "188/188 - 34s - loss: 0.4578 - accuracy: 0.8446 - val_loss: 0.8465 - val_accuracy: 0.7397 - 34s/epoch - 179ms/step\n",
            "Epoch 13/60\n",
            "188/188 - 30s - loss: 0.4163 - accuracy: 0.8621 - val_loss: 0.7970 - val_accuracy: 0.7490 - 30s/epoch - 160ms/step\n",
            "Epoch 14/60\n",
            "188/188 - 29s - loss: 0.3669 - accuracy: 0.8776 - val_loss: 0.8060 - val_accuracy: 0.7523 - 29s/epoch - 154ms/step\n",
            "Epoch 15/60\n",
            "188/188 - 32s - loss: 0.3038 - accuracy: 0.9000 - val_loss: 0.8137 - val_accuracy: 0.7557 - 32s/epoch - 170ms/step\n",
            "Epoch 16/60\n",
            "188/188 - 32s - loss: 0.3210 - accuracy: 0.8950 - val_loss: 0.8666 - val_accuracy: 0.7377 - 32s/epoch - 168ms/step\n",
            "Epoch 17/60\n",
            "188/188 - 29s - loss: 0.2695 - accuracy: 0.9117 - val_loss: 0.8948 - val_accuracy: 0.7410 - 29s/epoch - 155ms/step\n",
            "Epoch 18/60\n",
            "188/188 - 31s - loss: 0.2430 - accuracy: 0.9209 - val_loss: 0.8413 - val_accuracy: 0.7610 - 31s/epoch - 164ms/step\n",
            "Epoch 19/60\n",
            "188/188 - 31s - loss: 0.2287 - accuracy: 0.9217 - val_loss: 0.8249 - val_accuracy: 0.7697 - 31s/epoch - 165ms/step\n",
            "Epoch 20/60\n",
            "188/188 - 33s - loss: 0.1942 - accuracy: 0.9361 - val_loss: 0.8687 - val_accuracy: 0.7764 - 33s/epoch - 175ms/step\n",
            "Epoch 21/60\n",
            "188/188 - 32s - loss: 0.1883 - accuracy: 0.9396 - val_loss: 0.7735 - val_accuracy: 0.7770 - 32s/epoch - 169ms/step\n",
            "Epoch 22/60\n",
            "188/188 - 29s - loss: 0.1961 - accuracy: 0.9317 - val_loss: 0.8592 - val_accuracy: 0.7690 - 29s/epoch - 156ms/step\n",
            "Epoch 23/60\n",
            "188/188 - 31s - loss: 0.1532 - accuracy: 0.9486 - val_loss: 0.9111 - val_accuracy: 0.7737 - 31s/epoch - 163ms/step\n",
            "Epoch 24/60\n",
            "188/188 - 33s - loss: 0.1827 - accuracy: 0.9396 - val_loss: 0.9490 - val_accuracy: 0.7503 - 33s/epoch - 173ms/step\n",
            "Epoch 25/60\n",
            "188/188 - 31s - loss: 0.1652 - accuracy: 0.9461 - val_loss: 0.8808 - val_accuracy: 0.7724 - 31s/epoch - 168ms/step\n",
            "Epoch 26/60\n",
            "188/188 - 29s - loss: 0.1273 - accuracy: 0.9594 - val_loss: 0.8686 - val_accuracy: 0.7877 - 29s/epoch - 153ms/step\n",
            "Epoch 27/60\n",
            "188/188 - 31s - loss: 0.1493 - accuracy: 0.9539 - val_loss: 1.0166 - val_accuracy: 0.7397 - 31s/epoch - 167ms/step\n",
            "Epoch 28/60\n",
            "188/188 - 32s - loss: 0.1514 - accuracy: 0.9493 - val_loss: 0.8406 - val_accuracy: 0.7837 - 32s/epoch - 171ms/step\n",
            "Epoch 29/60\n",
            "188/188 - 31s - loss: 0.1010 - accuracy: 0.9668 - val_loss: 0.8559 - val_accuracy: 0.7817 - 31s/epoch - 167ms/step\n",
            "Epoch 30/60\n",
            "188/188 - 30s - loss: 0.0884 - accuracy: 0.9716 - val_loss: 0.7839 - val_accuracy: 0.8084 - 30s/epoch - 161ms/step\n",
            "Epoch 31/60\n",
            "188/188 - 30s - loss: 0.1082 - accuracy: 0.9659 - val_loss: 0.9725 - val_accuracy: 0.7664 - 30s/epoch - 161ms/step\n",
            "Epoch 32/60\n",
            "188/188 - 32s - loss: 0.1050 - accuracy: 0.9643 - val_loss: 0.8468 - val_accuracy: 0.7971 - 32s/epoch - 172ms/step\n",
            "Epoch 33/60\n",
            "188/188 - 33s - loss: 0.1121 - accuracy: 0.9634 - val_loss: 0.8400 - val_accuracy: 0.8071 - 33s/epoch - 177ms/step\n",
            "Epoch 34/60\n",
            "188/188 - 30s - loss: 0.0635 - accuracy: 0.9816 - val_loss: 0.8330 - val_accuracy: 0.8077 - 30s/epoch - 159ms/step\n",
            "Epoch 35/60\n",
            "188/188 - 29s - loss: 0.0708 - accuracy: 0.9771 - val_loss: 0.9430 - val_accuracy: 0.7957 - 29s/epoch - 156ms/step\n",
            "Epoch 36/60\n",
            "188/188 - 32s - loss: 0.1049 - accuracy: 0.9658 - val_loss: 0.9380 - val_accuracy: 0.7777 - 32s/epoch - 168ms/step\n",
            "Epoch 37/60\n",
            "188/188 - 32s - loss: 0.1715 - accuracy: 0.9412 - val_loss: 0.9342 - val_accuracy: 0.7884 - 32s/epoch - 169ms/step\n",
            "Epoch 38/60\n",
            "188/188 - 29s - loss: 0.0674 - accuracy: 0.9781 - val_loss: 0.8565 - val_accuracy: 0.8144 - 29s/epoch - 154ms/step\n",
            "Epoch 39/60\n",
            "188/188 - 30s - loss: 0.0434 - accuracy: 0.9878 - val_loss: 0.9588 - val_accuracy: 0.7951 - 30s/epoch - 161ms/step\n",
            "Epoch 40/60\n",
            "188/188 - 32s - loss: 0.0262 - accuracy: 0.9927 - val_loss: 0.8994 - val_accuracy: 0.8211 - 32s/epoch - 171ms/step\n",
            "Epoch 41/60\n",
            "188/188 - 33s - loss: 0.0736 - accuracy: 0.9793 - val_loss: 0.9024 - val_accuracy: 0.7937 - 33s/epoch - 178ms/step\n",
            "Epoch 42/60\n",
            "188/188 - 30s - loss: 0.0825 - accuracy: 0.9710 - val_loss: 0.9663 - val_accuracy: 0.7864 - 30s/epoch - 159ms/step\n",
            "Epoch 43/60\n",
            "188/188 - 30s - loss: 0.1173 - accuracy: 0.9629 - val_loss: 0.8259 - val_accuracy: 0.8231 - 30s/epoch - 158ms/step\n",
            "Epoch 44/60\n",
            "188/188 - 32s - loss: 0.0683 - accuracy: 0.9790 - val_loss: 0.8668 - val_accuracy: 0.8004 - 32s/epoch - 171ms/step\n",
            "Epoch 45/60\n",
            "188/188 - 31s - loss: 0.0559 - accuracy: 0.9826 - val_loss: 0.9398 - val_accuracy: 0.7997 - 31s/epoch - 167ms/step\n",
            "Epoch 46/60\n",
            "188/188 - 31s - loss: 0.0667 - accuracy: 0.9806 - val_loss: 1.0019 - val_accuracy: 0.7797 - 31s/epoch - 167ms/step\n",
            "Epoch 47/60\n",
            "188/188 - 28s - loss: 0.0362 - accuracy: 0.9897 - val_loss: 0.8747 - val_accuracy: 0.8044 - 28s/epoch - 150ms/step\n",
            "Epoch 48/60\n",
            "188/188 - 33s - loss: 0.0128 - accuracy: 0.9972 - val_loss: 0.8980 - val_accuracy: 0.8138 - 33s/epoch - 173ms/step\n",
            "Epoch 49/60\n",
            "188/188 - 33s - loss: 0.0069 - accuracy: 0.9987 - val_loss: 0.9014 - val_accuracy: 0.8231 - 33s/epoch - 174ms/step\n",
            "Epoch 50/60\n",
            "188/188 - 32s - loss: 0.0043 - accuracy: 0.9993 - val_loss: 0.9195 - val_accuracy: 0.8238 - 32s/epoch - 168ms/step\n",
            "Epoch 51/60\n",
            "188/188 - 29s - loss: 0.0030 - accuracy: 0.9992 - val_loss: 0.9471 - val_accuracy: 0.8271 - 29s/epoch - 154ms/step\n",
            "Epoch 52/60\n",
            "188/188 - 31s - loss: 0.0029 - accuracy: 0.9993 - val_loss: 0.9664 - val_accuracy: 0.8211 - 31s/epoch - 165ms/step\n",
            "Epoch 53/60\n",
            "188/188 - 32s - loss: 0.0052 - accuracy: 0.9990 - val_loss: 1.0086 - val_accuracy: 0.8231 - 32s/epoch - 172ms/step\n",
            "Epoch 54/60\n",
            "188/188 - 34s - loss: 0.0026 - accuracy: 0.9995 - val_loss: 1.0163 - val_accuracy: 0.8258 - 34s/epoch - 180ms/step\n",
            "Epoch 55/60\n",
            "188/188 - 33s - loss: 0.0135 - accuracy: 0.9953 - val_loss: 1.3029 - val_accuracy: 0.7717 - 33s/epoch - 176ms/step\n",
            "Epoch 56/60\n",
            "188/188 - 29s - loss: 0.3260 - accuracy: 0.8973 - val_loss: 1.0037 - val_accuracy: 0.7777 - 29s/epoch - 157ms/step\n",
            "Epoch 57/60\n",
            "188/188 - 30s - loss: 0.1782 - accuracy: 0.9411 - val_loss: 0.8400 - val_accuracy: 0.8057 - 30s/epoch - 160ms/step\n",
            "Epoch 58/60\n",
            "188/188 - 32s - loss: 0.0548 - accuracy: 0.9843 - val_loss: 0.8382 - val_accuracy: 0.8111 - 32s/epoch - 171ms/step\n",
            "Epoch 59/60\n",
            "188/188 - 32s - loss: 0.0477 - accuracy: 0.9848 - val_loss: 0.8502 - val_accuracy: 0.8191 - 32s/epoch - 168ms/step\n",
            "Epoch 60/60\n",
            "188/188 - 32s - loss: 0.0193 - accuracy: 0.9960 - val_loss: 0.8582 - val_accuracy: 0.8184 - 32s/epoch - 169ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3079: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "test_loss, test_acc = model.evaluate(x_test, y_test, verbose=2)\n",
        "print(\"\\nTest accuracy:\", test_acc)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "svVD2Z8hNUEG",
        "outputId": "355dac3a-13b6-43a5-cca9-2710817fd51f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "79/79 - 3s - loss: 0.8375 - accuracy: 0.8174 - 3s/epoch - 35ms/step\n",
            "\n",
            "Test accuracy: 0.8173808455467224\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def predict(model, X, y):\n",
        "    \"\"\"Predict a single sample using the trained model.\n",
        "    :param model: Trained classifier\n",
        "    :param X: Input data\n",
        "    :param y (int): Target\n",
        "    \"\"\"\n",
        "\n",
        "    # add a dimension to input data for sample - model.predict() expects a 4d array in this case\n",
        "    X = X[np.newaxis, ...]  # array shape (1, 130, 13, 1)\n",
        "\n",
        "    # perform prediction\n",
        "    prediction = model.predict(X)\n",
        "\n",
        "    # get index with max value\n",
        "    predicted_index = np.argmax(prediction, axis=1)\n",
        "\n",
        "    # get mappings for target and predicted label\n",
        "    target = z[y]\n",
        "    predicted = z[predicted_index]\n",
        "\n",
        "    print(\"Target: {}, Predicted label: {}\".format(target, predicted))\n",
        "X_to_predict = x_test[199]\n",
        "y_to_predict = y_test[199]\n",
        "\n",
        "# predict sample\n",
        "predict(model, X_to_predict, y_to_predict)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ic9Z5X_aeBG8",
        "outputId": "a1f96d72-8824-440e-b706-75e345167b31"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 1s 894ms/step\n",
            "Target: pop, Predicted label: ['pop']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import f1_score, confusion_matrix\n",
        "# Predictions on the test set\n",
        "y_pred = np.argmax(model.predict(x_test), axis=1)\n",
        "\n",
        "# Calculate F1 score\n",
        "f1 = f1_score(y_test, y_pred, average='weighted')\n",
        "print(\"F1 Score:\", f1)\n",
        "\n",
        "# Calculate confusion matrix\n",
        "conf_matrix = confusion_matrix(y_test, y_pred)\n",
        "print(\"Confusion Matrix:\")\n",
        "print(conf_matrix)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I2CRphL2lTCX",
        "outputId": "59f0854a-ba7d-47ec-8288-f05c3f0ded8a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "79/79 [==============================] - 6s 79ms/step\n",
            "F1 Score: 0.8167335257591312\n",
            "Confusion Matrix:\n",
            "[[164   2  13   0  10   5   6   2  27   0]\n",
            " [  1 219   5   0   2   3   9  14   2   2]\n",
            " [  7   6 185  13   6   8  19  25   2   0]\n",
            " [  0   0  10 225   4   0   1   3   0   1]\n",
            " [  4   1   9   0 205   4   9   2   2   2]\n",
            " [  4   3   8   0   3 206  11  13   1   3]\n",
            " [  7   4  13   0  10   4 190   6   1   2]\n",
            " [  0   7  12   4   0   3   6 236   0   7]\n",
            " [  5   0   3   0   0   0   2   4 243   0]\n",
            " [  0  13   7   4   6  14   6  17   2 168]]\n"
          ]
        }
      ]
    }
  ]
}